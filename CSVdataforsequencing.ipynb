{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSVdataforsequencing.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/themidwestcanapps/pyAudioAnalysis/blob/master/CSVdataforsequencing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHSM4quJWlwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sklearn \n",
        "!pip install pyAudioAnalysis\n",
        "!pip install hmmlearn\n",
        "!pip install eyed3\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp5lb7hcXh8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone -l -s git://github.com/tyiannak/pyAudioAnalysis.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS_aH6c7M16t",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydM2m5YBX6GJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -e  ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX4upKWxYtem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyAudioAnalysis\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU-0uqwDVwlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np \n",
        "import sklearn.cluster\n",
        "import scipy \n",
        "import os \n",
        "from scipy.spatial import distance \n",
        "import matplotlib.pyplot as plt \n",
        "import csv\n",
        "import os.path\n",
        "import sklearn \n",
        "import sklearn.cluster \n",
        "import hmmlearn.hmm \n",
        "import pickle as cPickle\n",
        "import glob \n",
        "\n",
        "def smoothMovingAvg(inputSignal, windowLen=11):\n",
        "    windowLen = int(windowLen)\n",
        "    if inputSignal.ndim != 1:\n",
        "        raise ValueError(\"\")\n",
        "    if inputSignal.size < windowLen:\n",
        "        raise ValueError(\"Input Vector needs to be bigger than window size\")\n",
        "    if windowLen < 3:\n",
        "        return inputSignal \n",
        "    s = np.r_[2*inputSignal[0] - inputSignal[windowLen-1::-1],\n",
        "              inputSignal, 2*inputSignal[-1]-inputSignal[-1:-windowLen:-1]]\n",
        "    w = np.ones(windowLen, 'd')\n",
        "    y = np.convolve(w/w.sum(), s, mode='same')\n",
        "    return y[windowLen:-windowLen+1]\n",
        "\n",
        "def selfSimilarityMatrix(featureVectors):\n",
        "    [nDims, nVectors] = featureVectors.shape\n",
        "    [featureVectors2, MEAN, STD] = aT.normalizeFeatures([featureVectors.T])\n",
        "    S = 1.0 - distance.squareform(distance.pdist(featureVectors2.T, 'cosine'))\n",
        "    return S\n",
        "\n",
        "def flags2segs(flags, window):\n",
        "    preFlag = 0 \n",
        "    cur_flag = 0 \n",
        "    n_segs = 0 \n",
        "\n",
        "    cur_vals = flags[cur_flag]\n",
        "    segsList = []\n",
        "    classes = []\n",
        "    while (cur_flag < len(flags) - 1):\n",
        "        stop = 0 \n",
        "        preFlag = cur_flag\n",
        "        preVal = cur_val\n",
        "        while (stop == 0):\n",
        "            cur_flag = cur_flag + 1\n",
        "            tempVal = flags[cur_flag]\n",
        "            if ((tempVal != cur_val) | (cur_flag == len(flags) - 1)):\n",
        "                n_segs = n_segs + 1\n",
        "                stop = 1\n",
        "                cur_seg = cur_val\n",
        "                cur_val = flags[cur_flag]\n",
        "                segsList.append((cur_flag * window))\n",
        "                classes.append(preVal)\n",
        "    segs = np.zeros((len(segsList), 2))\n",
        "\n",
        "    for i in range(len(segsLIst)):\n",
        "        if i > 0:\n",
        "            segs[i, 0] = segsList[i-1]\n",
        "        segs[i, 1] = segsList[i]\n",
        "    return (segs, classes)\n",
        "\n",
        "def segs2flags(seg_start, seg_end, seg_label, win_size):\n",
        "    flags = []\n",
        "    class_names = list(set(seg_label))\n",
        "    curPos = win_size / 2.0\n",
        "    while curPos < seg_end[-1]:\n",
        "        for i in range(len(seq_start)):\n",
        "            if curPos > seg_start[i] and curPos <= seg_end[i]:\n",
        "                break\n",
        "        flags.append(class_names.index(seg_label[i]))\n",
        "        curPos += win_size\n",
        "    return np.array(flags), class_names\n",
        "\n",
        "def computePreRec(cm, class_names):\n",
        "    n_classes = cm.shape[0]\n",
        "    if len(class_names) != n_classes:\n",
        "        print(\"Error in computePreRec! Confusion matrix and class_names\"\n",
        "              \"list must be of the same size!\")\n",
        "        return \n",
        "    precision = []\n",
        "    recall = []\n",
        "    f1 = []\n",
        "    for i, c in enumerate(class_names):\n",
        "        precision.append(cm[i,i] / np.sum(cm[:,i]))\n",
        "        recall.append(cm[i,i] / np.sum(cm[i,:]))\n",
        "        f1.append( 2 * precision[-1] * recall[-1] / (precision[-1] + recall[-1]))\n",
        "    return recall, precision, f1\n",
        "\n",
        "def readSegmentGT(gt_file):\n",
        "    f = open(gt_file, 'rt')\n",
        "    reader = csv.reader(f, delimiter=',')\n",
        "    seg_start = []\n",
        "    seg_end = []\n",
        "    seg_label = []\n",
        "    for row in readers:\n",
        "        if len(row) == 3:\n",
        "            seg_start.append(float(row[0]))\n",
        "            seg_end.append(float(row[1]))\n",
        "            seg_label.append((row[2]))\n",
        "    return np.array(seg_start), np.array(seg_end), seg_label\n",
        "\n",
        "\n",
        "def plotSegmentationResults(flags_ind, flags_ind_gt, class_names, mt_step, ONLY_EVALUATE=False):\n",
        "    flags = [class_names[int(f)] for f in flags_ind]\n",
        "    (segs, classes) = flags2segs(flags,mt_step)\n",
        "    min_len = min(flags_ind.shape[0], flags_ind_get.shape[0])\n",
        "    if min_len > 0:\n",
        "        accuracy = np.sum(flags_ind[0:min_len] ==\n",
        "                          flags_ind_gt[0:min_len]) / float(min_len)\n",
        "    else:\n",
        "        accuracy = -1\n",
        "\n",
        "    if not ONLY_EVALUATE:\n",
        "        duration = segs[-1,-1]\n",
        "        s_percentages = np.zeros((len(class_names), 1))\n",
        "        percentages = np.zeros((len(class_names), 1))\n",
        "        av_durations = numpy.zeros((len(class_names), 1))\n",
        "\n",
        "        for iSeg in range(segs.shape[0]):\n",
        "            s_percentages[class_names.index(classes[iSeg])] += \\\n",
        "                (segs[iSeg, 1]-segs[iSeg, 0])\n",
        "        \n",
        "        for i in range(s_percentages.shape[0]):\n",
        "            percentages[i] = 100.0 * s_percentages[i] / duration \n",
        "            S = sum(1 for c in classes if c == class_names[i])\n",
        "            if S > 0:\n",
        "                av_durations[i] = s_percentages[i] / S\n",
        "            else:\n",
        "                av_durations[i] = 0.0\n",
        "            \n",
        "        for i in range(percentages.shape[0]):\n",
        "            print(class_names[i], percentages[i], av_durations[i])\n",
        "\n",
        "        font = {'size': 10}\n",
        "        plt.rc('font', **font)\n",
        "\n",
        "        fig = plt.figure()\n",
        "        ax1 = fig.add_subplot(211)\n",
        "        ax1.set_ytick(np.array(range(len(class_names))))\n",
        "        ax1.axis((0, duration, -1, len(class_names)))\n",
        "        ax1.set_yticklabels(class_names)\n",
        "        ax1.plot(np.array(range(len(flags_ind))) * mt_step +\n",
        "                 mt_step / 2.0, flags_ind)\n",
        "        if flags_ind_gt.shape[0] > 0:\n",
        "            ax1.plot(np.array(range(len(flags_ind_gt))) * mt_step +\n",
        "                     mt_step / 2.0, flags_ind_gt + 0.05, '--r')\n",
        "        plt.xlabel('time(seconds)')\n",
        "        if accuracy >= 0:\n",
        "            plt.title('Accuracy = {0:1f}%'.format(100.0 * accuracy))\n",
        "\n",
        "        ax2 = fig.add_subplot(223)\n",
        "        plt.title(\"Classes percentage durations\")\n",
        "        ax2.axis((0, len(class_names) + 1, 0, 100))\n",
        "        ax2.set_xticks(np.array(range(len(class_names) + 1)))\n",
        "        ax2.set_xticklabels([\" \"] + class_names)\n",
        "        ax2.bar(np.array(range(len(class_names))) + 0.5, percentages)\n",
        "\n",
        "        ax3 = fig.add_subplot(224)\n",
        "        plt.title(\"Segment average durration per class\")\n",
        "        ax3.axis((0, len(class_names) +1, 0, av_durations.max()))\n",
        "        ax3.set_xticks(np.array(range(len(class_names) + 1)))\n",
        "        ax3.set_xticklabels([\" \"] + class_names)\n",
        "        ax3.bar(np.array(range(len(class_names))) + 0.5, av_durations)\n",
        "        plt.show()\n",
        "    return accuracy\n",
        "\n",
        "def evaluateSpeakerDiarization(flags, flags_gt):\n",
        "\n",
        "    min_len = min(flags.shape[0], flags_gt.shape[0])\n",
        "    flags = flags[0:min_len]\n",
        "    flags_gt = flags_gt[0:min_len]\n",
        "\n",
        "    u_flags = np.unique(flags)\n",
        "    u_flags_gt = np.unique(flags_gt)\n",
        "\n",
        "    #compute contigency table:\n",
        "    c_matrix = np.zeros((u_flags.shape[0], u_flags_gt.shape[0]))\n",
        "    for i in range(min_len):\n",
        "        c_matrix[int(np.nonzero(u_flags == flags[i])[0]),\n",
        "                 int(np.nonzero(u_flags_gt == flags_gt[i])[0])] += 1.0\n",
        "\n",
        "    Nc, Ns = c_matrix.shape\n",
        "    N_s = np.sum(c_matrix, axis=0)\n",
        "    N_c = np.sum(c_matrix, axis=1)\n",
        "    N = np.sum(c_matrix)\n",
        "\n",
        "    purity_clust = np.zeros((Nc, ))\n",
        "    purity_speak = np.zeros((Ns, ))\n",
        "    #compute cluster purity:\n",
        "    for i in range(Nc):\n",
        "        purity_clust[i] = np.max((c_matrix[i, :])) / (N_c[i])\n",
        "\n",
        "    for j in range(Ns):\n",
        "        purity_speak[j] = np.max((c_matrix[:, j])) / (N_s[j])\n",
        "\n",
        "    purity_cluster_m = np.sum(purity_clust * N_c) / N\n",
        "    purity_cluster_m = np.sum(purity_clust * N_s) / N\n",
        "\n",
        "    return purity_cluster_m, purity_speaker_m\n",
        "\n",
        "def trainHMM_computeStatistics(features, labels):\n",
        "    #279\n",
        "    u_labels = np.unique(labels)\n",
        "    n_comps = len(u_labels)\n",
        "\n",
        "    n_feats = features.shape[0]\n",
        "\n",
        "    if features.shape[1] < labels.shape[0]:\n",
        "        print(\"trainHMM warning: number of short-term feature vectors \"\n",
        "              \"must be greater or equal to the labels length\")\n",
        "        labels = labels[0:features.shape[1]]\n",
        "\n",
        "    #compute prior probabilities:\n",
        "    start_prob = np.zeros((n_comps,))\n",
        "    for i, u in enumerate(u_labels):\n",
        "        start_prob[i] =np.count_nonzero(labels == u)\n",
        "    #normalize prior porbabilities:\n",
        "    start_prob = start_prob / start_prob.sum()\n",
        "\n",
        "    #compute transition matrix:\n",
        "    transmat = np.zeros((n_comps, n_comps))\n",
        "    for i in range(labels.shape[0]-1):\n",
        "        transmat[int(labels[i]), int(labels[i + 1])] += 1\n",
        "    #normalize rows of transition matrix:    \n",
        "    for i in range(n_comps):\n",
        "        transmat[i, :] /= transmat[i, :].sum()\n",
        "\n",
        "    means = np.zeros((n_comps, n_feats))\n",
        "    for i in range(n_comps):\n",
        "        means[i, :] = np.matrix(features[:,\n",
        "                                np.nonzero(labels ==\n",
        "                                           u_labels[i])[0]].mean(axis=1))\n",
        "    cov = np.zeros((n_comps, n_feats))\n",
        "    for i in range(n_comps):\n",
        "        cov[i, :] = np.std(features[:, np.nonzero(labels ==\n",
        "                                                  u_labels[i])[0]],\n",
        "                           axis=1)\n",
        "    return start_prob, transmat, means, cov\n",
        "\n",
        "def trainHMM_fromFile(wav_file, gt_file, hmm_model_name, mt_win, mt_step):\n",
        "    #334\n",
        "    [seg_start, seg_end, seg_labs] = readSegmentGT(gt_file)\n",
        "    flags, class_names = segs2flags(seg_start, seg_end, seg_labs, mt_step)\n",
        "    [fs, x] = audioBasicIO.readAudioFile(wav_file)\n",
        "    [F, _, _] = aF.matFeatureExtraction(x, fs, mt_win * fs, mt_step * fs,\n",
        "                                        round(fs * 0.050), round(fs * 0.050))\n",
        "    start_prob, transmat, means, cov = trainHMM_computeStatistics(F, flags)\n",
        "\n",
        "    hmm.startprob_ = start_prob\n",
        "    hmm.transmat_ = transmat\n",
        "    hmm.means_ = means\n",
        "    hmm.covars_ = cov \n",
        "\n",
        "    fo = open(hmm_model_name, \"wb\")\n",
        "    cPickle.dump(hmm, fo, protocol=cPickle.HIGHEST_PROTOCOL)\n",
        "    cPickle.dump(class_names, fo, protocol=cPickle.HIGHEST_PROTOCOL)\n",
        "    cPickle.dump(mt_win, fo, protocol=cPickle.HIGHEST_PROTOCOL)\n",
        "    cPickle.dump(mt_step, fo, protocol=cPickle.HIGHEST_PROTOCOL)\n",
        "    fo.close()\n",
        "\n",
        "    return hmm, class_names\n",
        "\n",
        "def trainHMM_fromDir(dirPath, hmm_model_name, mt_win, mt_step):\n",
        "    #374\n",
        "    flags_all = numpy.array([])\n",
        "    classes_all = []\n",
        "    for i, f in enumerate(glob.glob(dirPath + os.sep + '*.wav')):\n",
        "        #for each Wav file\n",
        "        wav_file = f\n",
        "        gt_file = f.replace('.wav', '.segments')\n",
        "        if not os.path.isfile(gt_file):\n",
        "            continue\n",
        "        [seg_start, seg_end, seg_labs] = readSegmentGT(gt_file)\n",
        "        flags, class_names = segs2flags(seg_start, seg_end, seg_labs, mt_step)\n",
        "        for c in class_names:\n",
        "            #update class names:\n",
        "            if c not in classes_all:\n",
        "                classes_all.append(c)\n",
        "        [fs, x] = audioBasicIO.readAudioFile(wav_file)\n",
        "        [F, _, _] = aF.mtFeatureExtraction(x, fs, mt_win * fs,\n",
        "                                           mt_step * fs, round(fd * 0.050),\n",
        "                                           round(fd * 0.050))\n",
        "        \n",
        "        lenF = F.shape[1]\n",
        "        lenL = len(flags)\n",
        "        min_sm = min(lenF, lenL)\n",
        "        F = F[:, 0:min_sm]\n",
        "        flags = flags[0:min_sm]\n",
        "\n",
        "        flagsNew = []\n",
        "        for j, f1 in enumerate(flags):\n",
        "            # append features and labels\n",
        "            flagsNew.append(classes_all.index(class_names[flags[j]]))\n",
        "        \n",
        "        flags_all = np.append(flags_all, np.array(flagsNew))\n",
        "\n",
        "        if i == 0:\n",
        "            f_all = F\n",
        "        else:\n",
        "            f_all = np.concatenate((f_all, F), axis=1)\n",
        "    start_prob, transmat, means, cov = trainHMM_computeStatistics(f_all, flags_all)\n",
        "        # compute HMM statistics\n",
        "    hmm = hmmlearn.hmm.GaussianHMM(start_prob.shape[0], \"diag\")\n",
        "    # train HMM\n",
        "    hmm.startprob_ = start_prob\n",
        "    hmm.transmat_ = transmat\n",
        "    hmm.means_ = means\n",
        "    hmm.covars_ = cov\n",
        "\n",
        "    fo = open(hmm_model_name, \"wb\")         #save HMM model\n",
        "    cPickle.dump(hmm, fo, protocol=cPickle.HIGHEST_PROTOCOL)\n",
        "    cPickle.dump(classes_all, fo, protocol=cPickle.HIGHEST_PROTOCOL)\n",
        "    cPickle.dump(mt_win, fo, protocol=cPickle.HIGHEST_PROTOCOL)\n",
        "    cPickle.dump(mt_step, fo, protocol=cPickle.HIGHEST_PROTOCOL)\n",
        "    fo.close()\n",
        "\n",
        "    return hmm, classes_all\n",
        "\n",
        "def hmmSegmentation(wav_file_name, hmm_model_name, plot_res=False,\n",
        "                    gt_file_name=\"\"):\n",
        "    [fs, x] = audioBasicIO.readAudioFile(wav_file_name)\n",
        "    try: \n",
        "        fo = open(hmm_model_name, \"rb\")\n",
        "    except IOError:\n",
        "        print(\"didn't find file\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        hmm = cPickle.load(fo)\n",
        "        classes_all = cPickle.load(fo)\n",
        "        mt_win = cPickle.load(fo)\n",
        "        mt_step = cPickle.load(fo)\n",
        "    except IOError:\n",
        "        print(\"didn't find file\")\n",
        "        return \n",
        "\n",
        "    try:\n",
        "        hmm = cPickle.load(fo)\n",
        "        classes_all = cPickle.load(fo)\n",
        "        mt_win = cPickle.load(fo)\n",
        "        mt_step = cPickle.load(fo)\n",
        "    except:\n",
        "        fo.close()\n",
        "    fo.close()\n",
        "\n",
        "    [Features, _, _] = aF.mtFeatureExtraction(x, fs, mt_win * fs, mt_step * fs,\n",
        "                                              round(fs * 0.050),\n",
        "                                              round(fs * 0.050))\n",
        "    flags_ind = hmm.predict(Features.T)\n",
        "    if os.path.isfile(gt_file_name):\n",
        "        [seg_start, seg_end, seg_labs] = readSegmentGT(gt_file_name)\n",
        "        flags_gt, class_names_gt = segs2flags(seg_start, seg_end, seg_labs,\n",
        "                                              mt_step)\n",
        "        flagsGTNew = []\n",
        "        for j, fl in enumerate(flags_gt):\n",
        "            #\"align\" labels with GT\n",
        "            if class_names_gt[flags_gt[j]] in classes_all:\n",
        "                flagsGTNew.append(classes_all.index(class_names_gt[flags_gt[j]]))\n",
        "            else:\n",
        "                flagsGTNew.append(-1)\n",
        "        cm = np.zeros((len(classes_all), len(classes_all)))\n",
        "        flags_ind_gt = np.array(flagsGTNew)\n",
        "        for i in range(min(flags_ind.shape[0], flags_ind_gt.shape[0])):\n",
        "            cm[int(flags_ind_gt[i]), int(flags_ind[i])] += 1\n",
        "    else:\n",
        "        flags_ind_gt = np.array([])\n",
        "    acc = plotSegmentationResults(flags_ind, flags_ind_gt, classes_all,\n",
        "                                  mt_step, not plot_res)\n",
        "    if acc >= 0:\n",
        "        print(\"Overall Accuracy: {0:2f}\".format(acc))\n",
        "        return (flags_ind, class_names_gt, acc, cm)\n",
        "    else:\n",
        "        return (flags_ind, classes_all, -1, -1)\n",
        "\n",
        "# def mtFileClassification(input_file, model_name, model_type,\n",
        "#                          plot_results=False, gt_file=\"\"):\n",
        "    #492\n",
        "    \n",
        "            \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            \n",
        "        \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-IHAVi0ukc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install simplejson"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iYQjY6sZSC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pydub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEUEQHqTG6d2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import aifc\n",
        "import ntpath\n",
        "import shutil\n",
        "import numpy as np\n",
        "from pydub import AudioSegment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMw3iP5TZXSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readAudioFile(path):\n",
        "    '''\n",
        "    This function returns a numpy array that stores the audio samples of a specified WAV of AIFF file\n",
        "    '''\n",
        "    extension = os.path.splitext(path)[1]\n",
        "\n",
        "    try:\n",
        "        #if extension.lower() == '.wav':\n",
        "            #[Fs, x] = wavfile.read(path)\n",
        "        if extension.lower() == '.aif' or extension.lower() == '.aiff':\n",
        "            s = aifc.open(path, 'r')\n",
        "            nframes = s.getnframes()\n",
        "            strsig = s.readframes(nframes)\n",
        "            x = np.frombuffer(strsig, np.short).byteswap()\n",
        "            Fs = s.getframerate()\n",
        "        elif extension.lower() == '.mp3' or extension.lower() == '.wav' or extension.lower() == '.au' or extension.lower() == '.ogg':            \n",
        "            try:\n",
        "                audiofile = AudioSegment.from_file(path)\n",
        "            #except pydub.exceptions.CouldntDecodeError:\n",
        "            except:\n",
        "                print(\"Error: file not found or other I/O error. \"\n",
        "                      \"(DECODING FAILED)\")\n",
        "                return (-1,-1)                \n",
        "\n",
        "            if audiofile.sample_width==2:                \n",
        "                data = np.frombuffer(audiofile._data, np.int16)\n",
        "            elif audiofile.sample_width==4:\n",
        "                data = np.frombuffer(audiofile._data, np.int32)\n",
        "            else:\n",
        "                return (-1, -1)\n",
        "            Fs = audiofile.frame_rate\n",
        "            x = []\n",
        "            for chn in list(range(audiofile.channels)):\n",
        "                x.append(data[chn::audiofile.channels])\n",
        "            x = np.array(x).T\n",
        "        else:\n",
        "            print(\"Error in readAudioFile(): Unknown file type!\")\n",
        "            return (-1,-1)\n",
        "    except IOError: \n",
        "        print(\"Error: file not found or other I/O error.\")\n",
        "        return (-1,-1)\n",
        "\n",
        "    if x.ndim==2:\n",
        "        if x.shape[1]==1:\n",
        "            x = x.flatten()\n",
        "\n",
        "    return (Fs, x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdBHE0HpjhQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def new_x_AudioFile(path):\n",
        "    '''\n",
        "    This function returns a numpy array that stores the audio samples of a specified WAV of AIFF file\n",
        "    '''\n",
        "    extension = os.path.splitext(path)[1]\n",
        "\n",
        "    try:\n",
        "        #if extension.lower() == '.wav':\n",
        "            #[Fs, x] = wavfile.read(path)\n",
        "        if extension.lower() == '.aif' or extension.lower() == '.aiff':\n",
        "            s = aifc.open(path, 'r')\n",
        "            nframes = s.getnframes()\n",
        "            strsig = s.readframes(nframes)\n",
        "            x = np.frombuffer(strsig, np.short).byteswap()\n",
        "            Fs = s.getframerate()\n",
        "        elif extension.lower() == '.mp3' or extension.lower() == '.wav' or extension.lower() == '.au' or extension.lower() == '.ogg':            \n",
        "            try:\n",
        "                audiofile = AudioSegment.from_file(path)\n",
        "            #except pydub.exceptions.CouldntDecodeError:\n",
        "            except:\n",
        "                print(\"Error: file not found or other I/O error. \"\n",
        "                      \"(DECODING FAILED)\")\n",
        "                return (-1,-1)                \n",
        "\n",
        "            if audiofile.sample_width==2:                \n",
        "                data = np.frombuffer(audiofile._data, np.int16)\n",
        "            elif audiofile.sample_width==4:\n",
        "                data = np.frombuffer(audiofile._data, np.int32)\n",
        "            else:\n",
        "                return (-1, -1)\n",
        "            Fs = audiofile.frame_rate\n",
        "            x = []\n",
        "            for chn in list(range(audiofile.channels)):\n",
        "                x.append(data[chn::audiofile.channels])\n",
        "            x = np.array(x).T\n",
        "        else:\n",
        "            print(\"Error in readAudioFile(): Unknown file type!\")\n",
        "            return (-1,-1)\n",
        "    except IOError: \n",
        "        print(\"Error: file not found or other I/O error.\")\n",
        "        return (-1,-1)\n",
        "\n",
        "    if x.ndim==2:\n",
        "        if x.shape[1]==1:\n",
        "            x = x.flatten()\n",
        "\n",
        "    return x    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jZ5DQ3Eb75n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stereo2mono(x):\n",
        "    '''\n",
        "    This function converts the input signal\n",
        "    (stored in a numpy array) to MONO (if it is STEREO)\n",
        "    '''\n",
        "    if isinstance(x, int):\n",
        "        return -1\n",
        "    if x.ndim==1:\n",
        "        return x\n",
        "    elif x.ndim==2:\n",
        "        if x.shape[1]==1:\n",
        "            return x.flatten()\n",
        "        else:\n",
        "            if x.shape[1]==2:\n",
        "                return ( (x[:,1] / 2) + (x[:,0] / 2) )\n",
        "            else:\n",
        "                return -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGB9XT5PcE9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print('as_mono:',stereo2mono(x_lln))\n",
        "\n",
        "# print('as_stereo:', new_x_AudioFile('/content/Hearthings_vaw_trim.wav'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukvqQuFolDH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjOUECj7EGzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fetch a single <1MB file using the raw GitHub URL.\n",
        "!curl --remote-name \\\n",
        "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "     --location 'https://raw.githubusercontent.com/themidwestcanapps/https-themidwestcanapps.github.io/master/Audio2019-10-21(04_37_08).wav'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm67rvIyyqey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "readAudioFile('Audio2019-10-21(04_37_08).wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlfM6ThryyIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# import wave\n",
        "# w = wave.open('Audio2019-10-21(04_37_08).wav', 'r')\n",
        "# for i in range(1):\n",
        "#     frame = w.readframes(1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTMlCdeCzuZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wave\n",
        "w = wave.open('Audio2019-10-21(04_37_08).wav', 'r')\n",
        "for i in range(w.getnframes()):\n",
        "    ### read 1 frame and the position will updated ###\n",
        "    frame = w.readframes(0)\n",
        "    \n",
        "    all_zero = True\n",
        "    for j in range(len(frame)):\n",
        "        # check if amplitude is greater than 0\n",
        "        if ord(frame[j]) > 0:\n",
        "            all_zero = False\n",
        "            break\n",
        "\n",
        "    if all_zero:\n",
        "        # perform your cut here\n",
        "        print('silence found at frame %s' % w.tell())\n",
        "        print('silence found at second %s' % (w.tell()/w.getframerate()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgRqtKr60fpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(frame))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "254IF3iR0iVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frame"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}